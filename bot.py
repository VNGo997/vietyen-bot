
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
vietyen-bot v4.3.6
- AI vi·∫øt l·∫°i b√†i ƒë·∫ßy ƒë·ªß (ti·∫øng Vi·ªát t·ª± nhi√™n) t·ª´ RSS ch√≠nh th·ªëng
- AI t·∫°o "T√≥m t·∫Øt ng·∫Øn g·ªçn" theo ng·ªØ c·∫£nh t·ª´ng b√†i
- AI t·∫°o "G·ª£i √Ω t·ª´ chuy√™n gia" theo n·ªôi dung ƒë√£ vi·∫øt l·∫°i
- B·ªè m·ª•c "Ngu·ªìn b√†i g·ªëc"; thay b·∫±ng ch√®n link ngu·ªìn v√†o "Ngu·ªìn tham kh·∫£o"
- Gi·ªØ: AI check, SEO + JSON-LD, 1 b√†i/ng√†y, draft mode, UI Visionary
"""
import os, re, json, html, random, requests, unicodedata, datetime
from typing import List, Dict, Any, Optional

try:
    import feedparser
except Exception:
    pass

CONFIG_PATH = os.environ.get("BOT_CONFIG_PATH", "config.json")

TAG_RE = re.compile(r"<[^>]+>")
IMG_RE = re.compile(r'<img[^>]+src="([^"]+)"', re.IGNORECASE)

def strip_html(raw_html: str) -> str:
    if not raw_html: return ""
    cleaned = re.sub(r"<(script|style)[^>]*>.*?</\\1>", "", raw_html, flags=re.I|re.S)
    text = TAG_RE.sub("", cleaned)
    text = re.sub(r"\\s+\\n", "\\n", text)
    text = re.sub(r"\\n{3,}", "\\n\\n", text).strip()
    return text

def first_img_src(raw_html: str) -> Optional[str]:
    if not raw_html: return None
    m = IMG_RE.search(raw_html)
    return m.group(1) if m else None

def load_config():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

def keyword_gate(text):
    t = text.lower()
    keys = ["s·ª©c kh·ªèe","y t·∫ø","b·ªánh","ƒëi·ªÅu tr·ªã","d·ª± ph√≤ng","tri·ªáu ch·ª©ng","ch·∫©n ƒëo√°n",
            "nh√£n khoa","b·ªù mi","kh√¥ m·∫Øt","vi√™m","thu·ªëc","b√°c sƒ©","b·ªánh vi·ªán",
            "ph√≤ng b·ªánh","vaccine","dinh d∆∞·ª°ng","tim m·∫°ch","da li·ªÖu","nhi khoa","c·∫•p c·ª©u","ƒëa ch·∫•n th∆∞∆°ng"]
    return any(k in t for k in keys)

def ai_health_gate(text, cfg):
    s = cfg.get("ai_check", {})
    if not s.get("enabled"): return True
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key: return keyword_gate(text)
    try:
        r = requests.post("https://api.openai.com/v1/chat/completions",
            headers={"Authorization": "Bearer {}".format(api_key), "Content-Type": "application/json"},
            json={
                "model": s.get("model", "gpt-4o-mini"),
                "messages": [
                    {"role": "system", "content": "Answer Y or N only."},
                    {"role": "user", "content": s.get("prompt","") + "\\n\\n" + text[:6000]}
                ],
                "temperature": 0
            }, timeout=30)
        ans = r.json()["choices"][0]["message"]["content"].strip().upper()
        return ans.startswith("Y")
    except Exception:
        return keyword_gate(text)

# -------- AI helpers --------
def call_openai(messages, model="gpt-4o-mini", temperature=0.4, timeout=45):
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return None
    try:
        r = requests.post("https://api.openai.com/v1/chat/completions",
            headers={"Authorization": "Bearer {}".format(api_key), "Content-Type":"application/json"},
            json={"model": model, "messages": messages, "temperature": temperature},
            timeout=timeout)
        return r.json()["choices"][0]["message"]["content"].strip()
    except Exception:
        return None

def ai_compose_full_article(title: str, source_text: str) -> str:
    """
    Vi·∫øt l·∫°i to√†n b·ªô b√†i theo phong c√°ch Visionary.
    N·∫øu kh√¥ng c√≥ API key, d√πng fallback m·ªü r·ªông n·ªôi dung an to√†n.
    """
    sys = "B·∫°n l√† bi√™n t·∫≠p vi√™n y t·∫ø vi·∫øt ti·∫øng Vi·ªát t·ª± nhi√™n, ch√≠nh x√°c, t√¥n tr·ªçng ngu·ªìn."
    user = (
        "Vi·∫øt l·∫°i TO√ÄN B·ªò B√ÄI theo phong c√°ch Visionary (y t·∫ø):\\n"
        "- Kh√¥ng tr√πng l·∫∑p; kh√¥ng b·ªãa chi ti·∫øt; ch·ªâ d·ª±a tr√™n n·ªôi dung ƒë√£ cho.\\n"
        "- B·ªë c·ª•c: M·ªü b√†i (1 ƒëo·∫°n) ‚Üí B·ªëi c·∫£nh/T√¨nh hu·ªëng (1‚Äì2 ƒëo·∫°n) ‚Üí Th√¥ng tin y khoa/c√°ch x·ª≠ tr√≠ (1‚Äì2 ƒëo·∫°n) ‚Üí L·ªùi khuy√™n th·ª±c t·∫ø (1 ƒëo·∫°n) ‚Üí K·∫øt (1 ƒëo·∫°n).\\n"
        "- Gi·ªçng vƒÉn t·ª± nhi√™n, th√¢n thi·ªán, tr√°nh gi·∫≠t t√≠t.\\n"
        "Ti√™u ƒë·ªÅ ngu·ªìn: {title}\\n\\nT√≥m t·∫Øt/ƒëo·∫°n tr√≠ch ngu·ªìn:\\n{src}"
    ).format(title=title, src=source_text[:2000])
    out = call_openai(
        [{"role":"system","content":sys},{"role":"user","content":user}]
    )
    if out: return out
    # Fallback (kh√¥ng API): n·ªõi r·ªông ph·∫ßn t√≥m t·∫Øt th√†nh 3‚Äì4 ƒëo·∫°n
    parts = source_text.split("\\n")
    intro = "B√†i vi·∫øt sau ƒë√¢y ƒë∆∞·ª£c t√≥m l∆∞·ª£c t·ª´ ngu·ªìn ch√≠nh th·ªëng, tr√¨nh b√†y theo ng√¥n ng·ªØ d·ªÖ hi·ªÉu."
    detail = source_text
    conclude = "CaÃÅc th√¥ng tin ch·ªâ mang t√≠nh tham kh·∫£o, ng∆∞·ªùi ƒë·ªçc n√™n t√¨m ƒë·∫øn c∆° s·ªü y t·∫ø khi c·∫ßn."
    return intro + "\\n\\n" + detail + "\\n\\n" + conclude

def ai_summary(title: str, full_text: str) -> str:
    """Sinh t√≥m t·∫Øt 1‚Äì2 c√¢u theo ng·ªØ c·∫£nh b√†i vi·∫øt."""
    user = (
        "T√≥m t·∫Øt ng·∫Øn g·ªçn (1‚Äì2 c√¢u) n·ªôi dung b√†i d∆∞·ªõi ƒë√¢y, ti·∫øng Vi·ªát t·ª± nhi√™n, kh√¥ng d√πng thu·∫≠t ng·ªØ kh√≥.\\n"
        "Ti√™u ƒë·ªÅ: {t}\\n\\nN·ªôi dung:\\n{c}"
    ).format(t=title, c=full_text[:2500])
    out = call_openai(
        [{"role":"system","content":"B·∫°n l√† bi√™n t·∫≠p vi√™n y t·∫ø t√≥m t·∫Øt s√∫c t√≠ch."},
         {"role":"user","content":user}], temperature=0.3, timeout=30
    )
    if out: return out
    # Fallback: l·∫•y 1‚Äì2 c√¢u ƒë·∫ßu
    sents = re.split(r"[\\.!?]\\s", full_text.strip())
    return (sents[0] + (". " + sents[1] if len(sents)>1 else "")).strip()

def ai_expert_tip_from_full(full_text: str, link_rule: Optional[Dict[str,str]]) -> str:
    """Sinh g·ª£i √Ω t·ª´ chuy√™n gia d·ª±a tr√™n b√†i ƒë√£ vi·∫øt l·∫°i."""
    extra = " S·∫£n ph·∫©m g·ª£i √Ω: {}".format(link_rule.get("title")) if link_rule else ""
    user = (
        "D·ª±a tr√™n n·ªôi dung sau, h√£y vi·∫øt 3‚Äì5 c√¢u l·ªùi khuy√™n th·ª±c t·∫ø, an to√†n, d·ªÖ l√†m cho ng∆∞·ªùi ƒë·ªçc. Tr√°nh ph√≥ng ƒë·∫°i.{extra}\\n\\n{c}"
        .format(extra=extra, c=full_text[:2500])
    )
    out = call_openai(
        [{"role":"system","content":"B·∫°n l√† chuy√™n gia y t·∫ø t∆∞ v·∫•n ng·∫Øn g·ªçn, th·ª±c t·∫ø."},
         {"role":"user","content":user}], temperature=0.35, timeout=30
    )
    if out: return html.escape(out.strip())
    # Fallback an to√†n
    tip = "Duy tr√¨ l·ªëi s·ªëng ƒëi·ªÅu ƒë·ªô, theo d√µi tri·ªáu ch·ª©ng v√† ∆∞u ti√™n chƒÉm s√≥c t·∫°i nh√†. N·∫øu kh√¥ng c·∫£i thi·ªán, h√£y li√™n h·ªá b√°c sƒ©."
    if link_rule: tip += " C√≥ th·ªÉ c√¢n nh·∫Øc s·∫£n ph·∫©m h·ªó tr·ª£: {}".format(html.escape(link_rule.get("title")))
    return tip

# -------- SEO helpers --------
def slugify(value: str) -> str:
    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')
    value = re.sub(r'[^a-zA-Z0-9\\-\\s]', '', value).strip().lower()
    value = re.sub(r'[\\s\\-]+', '-', value)
    return value[:80].strip('-') or 'bai-viet-suc-khoe'

def gen_seo(title: str, body: str) -> Dict[str, str]:
    base_title = title.strip()
    if len(base_title) > 60: base_title = base_title[:57].rstrip() + "..."
    sentences = re.split(r'[\\.!?]\\s', body)
    first = (sentences[0] or "").strip()
    if len(first) < 50 and len(sentences) > 1: first += ". " + sentences[1].strip()
    desc = first[:157].rstrip() + "..." if len(first) > 160 else first
    words = re.findall(r"[a-zA-Z√Ä-·ªπ0-9]{4,}", (title + " " + body).lower())
    common = {"v√†","cho","c·ªßa","khi","b·ªã","v·ªÅ","trong","ƒë∆∞·ª£c","b·ªánh","s·ª©c","kh·ªèe","ng∆∞·ªùi","b√†i","vi·∫øt","n√†y","c√°c","m·ªôt"}
    uniq = []
    for w in words:
        if w in common: continue
        if w not in uniq: uniq.append(w)
    keywords = ", ".join(uniq[:8])
    return {"seo_title": base_title, "seo_desc": desc, "seo_keywords": keywords, "seo_slug": slugify(title)}

def jsonld_article(cfg, title, desc, url, img):
    site = cfg.get("brand",{}).get("site_name","VietYenLTD Health Desk")
    logo = cfg.get("brand",{}).get("publisher_logo","")
    data = {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": title,
      "description": desc,
      "image": [img] if img else [],
      "datePublished": datetime.datetime.utcnow().isoformat() + "Z",
      "author": {"@type":"Organization","name": site},
      "publisher": {"@type":"Organization","name": site, "logo":{"@type":"ImageObject","url": logo}},
      "mainEntityOfPage": url or ""
    }
    import json as _json
    return '<script type="application/ld+json">{}</script>'.format(_json.dumps(data, ensure_ascii=False))

# -------- UI builder --------
def build_html(title, summary_text, full_text, hero_img, cfg, expert_tip_html, rule, source_url=None, seo=None):
    cap = "·∫¢nh minh ho·∫°: Unsplash"
    expert = '<div style="margin:26px 0;background:linear-gradient(135deg,#004aad,#0b73d5);color:#fff;border-radius:12px;padding:18px;"><div style="font-size:18px;font-weight:700;margin-bottom:6px">üí¨ G·ª£i √Ω t·ª´ chuy√™n gia</div><div style="line-height:1.7">{}</div>'.format(expert_tip_html)
    if rule:
        expert += '<div style="margin-top:10px">üåê Tham kh·∫£o: <a href="{}" style="color:#ffe07a;text-decoration:underline">{}</a></div>'.format(html.escape(rule["url"]), html.escape(rule["title"]))
    expert += '</div>'
    # Footer: ch·ªâ c√≤n "Ngu·ªìn tham kh·∫£o" + mi·ªÖn tr·ª´; ch√®n link ngu·ªìn t·∫°i ƒë√¢y
    ref = ' <a href="{}" target="_blank" rel="noopener">Xem b√†i g·ªëc</a>'.format(html.escape(source_url)) if source_url else ""
    footer = '<div style="border:1px solid #e8eefc;border-radius:12px;padding:14px 16px;background:#fbfdff;margin-top:24px"><p><span style="color:#004aad">üîó Ngu·ªìn tham kh·∫£o:</span> T·ªïng h·ª£p t·ª´ c√°c ngu·ªìn ch√≠nh th·ªëng v·ªÅ s·ª©c kh·ªèe.{}.</p><p style="color:#667;font-size:14px">‚ö†Ô∏è <strong>Mi·ªÖn tr·ª´ tr√°ch nhi·ªám:</strong> N·ªôi dung ch·ªâ tham kh·∫£o, kh√¥ng thay th·∫ø t∆∞ v·∫•n y khoa.</p></div>'.format(ref)

    # Convert paragraphs
    body_html = "<p>{}</p>".format(html.escape(full_text).replace("\\n\\n","</p><p>").replace("\\n","<br>"))
    sum_html = html.escape(summary_text)

    html_doc = "<figure><img src='{}' style='width:100%;border-radius:14px;'><figcaption>{}</figcaption></figure>".format(hero_img, cap)
    html_doc += "<div style='background:linear-gradient(90deg,#eaf2ff,#f7fbff);border:1px solid #d9e7ff;border-radius:12px;padding:14px 16px;margin:16px 0'><strong style='color:#004aad'>ü©∫ T√≥m t·∫Øt ng·∫Øn g·ªçn:</strong> {}</div>".format(sum_html)
    html_doc += body_html + expert + footer
    if seo:
        html_doc += jsonld_article(cfg, seo.get("seo_title",title), seo.get("seo_desc",""), "", hero_img)
    return html_doc

# -------- WP --------
def wp_create_draft(title, content, tags, cfg, seo=None):
    wp = os.environ.get("WP_URL","").rstrip("/")
    u = os.environ.get("WP_USERNAME")
    pw = os.environ.get("WP_APP_PASSWORD")
    if not (wp and u and pw):
        print("Thi·∫øu th√¥ng tin WordPress."); return None
    try:
        ids = []
        for t in tags:
            r=requests.get("{}/wp-json/wp/v2/tags".format(wp),params={"search":t,"per_page":1},auth=(u,pw),timeout=20)
            if r.ok and r.json(): ids.append(r.json()[0]["id"])
            else:
                cr=requests.post("{}/wp-json/wp/v2/tags".format(wp),json={"name":t},auth=(u,pw),timeout=20)
                if cr.ok: ids.append(cr.json()["id"])
        payload={"title": seo.get("seo_title",title) if seo else title,
                 "content": content,
                 "status": "draft",
                 "tags": ids}
        if seo:
            payload["excerpt"] = seo.get("seo_desc","")
            payload["slug"] = seo.get("seo_slug","")
        cat_id = cfg.get("category_id")
        if cat_id: payload["categories"] = [cat_id]
        c=requests.post("{}/wp-json/wp/v2/posts".format(wp),json=payload,auth=(u,pw),timeout=30)
        if c.ok: print("ƒê√£ t·∫°o b·∫£n nh√°p ID:",c.json().get("id"))
        else: print("L·ªói t·∫°o b√†i:",c.status_code,c.text[:300])
    except Exception as e: print("L·ªói WP:",e)

# -------- RSS --------
def fetch_rss(urls):
    try: import feedparser
    except: return []
    out=[]
    for u in urls:
        try:
            d=feedparser.parse(u)
            for e in d.entries[:10]:
                title=e.get("title","").strip()
                summary_html=e.get("summary","").strip()
                link=e.get("link","").strip()
                text=strip_html(summary_html) or title
                img=first_img_src(summary_html)
                out.append({"title":title,"content_text":text,"link":link,"rss_img":img})
        except Exception: pass
    return out

# -------- Main --------
def main():
    cfg=load_config()
    items=fetch_rss(cfg.get("rss_sources",[]))
    ok=[i for i in items if keyword_gate(i["title"]+" "+i["content_text"]) and ai_health_gate(i["title"]+" "+i["content_text"],cfg)]
    if not ok: print("Kh√¥ng c√≥ b√†i h·ª£p l·ªá."); return
    c=random.choice(ok)
    hero_img=(c.get("rss_img") or cfg.get("default_hero_url"))
    # 1) Vi·∫øt l·∫°i to√†n b·ªô b√†i
    full_text=ai_compose_full_article(c["title"], c["content_text"])
    # 2) T√≥m t·∫Øt ng·∫Øn g·ªçn theo ng·ªØ c·∫£nh
    summary=ai_summary(c["title"], full_text)
    # 3) N·ªôi li√™n k·∫øt + g·ª£i √Ω chuy√™n gia theo n·ªôi dung ƒë√£ vi·∫øt
    rule=None
    for r in cfg.get("internal_links", []):
        if any(k in full_text.lower() for k in r.get("keywords", [])): rule=r; break
    expert_tip=ai_expert_tip_from_full(full_text, rule)
    # 4) SEO
    seo=gen_seo(c["title"], full_text)
    # 5) Build HTML (kh√¥ng c√≥ "Ngu·ªìn b√†i g·ªëc"; link n·∫±m trong "Ngu·ªìn tham kh·∫£o")
    html_doc=build_html(c["title"], summary, full_text, hero_img, cfg, expert_tip, rule, source_url=c.get("link"), seo=seo)
    # 6) ƒêƒÉng nh√°p
    wp_create_draft(c["title"], html_doc, cfg.get("tags_by_name", []), cfg, seo=seo)

if __name__=="__main__": main()
